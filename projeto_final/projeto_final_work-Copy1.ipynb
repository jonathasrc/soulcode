{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfCv7aFr1EAp",
    "outputId": "ad7052ab-dce1-4e26-ab9e-0bdbb1d82198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "to72RTdV1HrB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.11/site-packages (1.3.8)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import math\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "from mysql.connector import Error\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "!pip install unidecode\n",
    "from unidecode import unidecode\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sqlalchemy import Column, Integer, Float, String, Boolean, DateTime, Text\n",
    "from sqlalchemy.orm import declarative_base\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials_path = \"/home/jovyan/code/.devcontainer/soulcode-434516-8f4db69ae452.json\"\n",
    "credentials_path = \"/home/jovyan/code/.devcontainer/soulcode-434516-8f4db69ae452.json\"\n",
    "# credentials_path = \"/home/jovyan/code/soulcode-434516-31276919e28c.json\"\n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YfltdB7i3JJI"
   },
   "outputs": [],
   "source": [
    "def fetch_data(url, headers=None):\n",
    "    try:\n",
    "      response = requests.get(url, headers=headers)\n",
    "      response.raise_for_status()\n",
    "      return response.json()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "      print(f\"HTTP error occurred: {e}\")\n",
    "      return None\n",
    "    except requests.exceptions.ConnectionError as e:\n",
    "      print(f\"connexion error occurred: {e}\")\n",
    "      return None\n",
    "    except requests.exceptions.Timeout as e:\n",
    "      print(f\"Request timed out: {e}\")\n",
    "      return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "      print(f\"Error fetching data from {url}: {e}\")\n",
    "      return None\n",
    "    \n",
    "def fetch_data_with_retry(url, headers=None, max_retries=3, retry_delay=5):\n",
    "    for _ in range(max_retries):\n",
    "        data = fetch_data(url, headers)\n",
    "        if data is not None:\n",
    "            return data\n",
    "        \n",
    "        print(f\"Retrying in {retry_delay} seconds...\")\n",
    "        time.sleep(retry_delay)\n",
    "    print(\"Max retries reached. Unable to fetch data.\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisição bem-sucedida!\n",
      "Dados obtidos: {'total': '0', 'perPage': 20, 'page': 1, 'lastPage': 0, 'data': []}\n"
     ]
    }
   ],
   "source": [
    "def login():\n",
    "    url_login = 'https://api.projectcor.com/v1/auth/login'\n",
    "    content = {\n",
    "        \"email\": \"academico@soulcode.com\",\n",
    "        \"password\": \"Admin@123\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url_login, json=content)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        token = response_json.get('token', {}).get('access_token')\n",
    "        refresh_token = response_json.get('token', {}).get('refreshToken')\n",
    "        if token and refresh_token:\n",
    "            return token, refresh_token\n",
    "        else:\n",
    "            print(\"Tokens não encontrados na resposta.\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(f\"Erro no login: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None, None\n",
    "\n",
    "def refresh_access_token(refresh_token):\n",
    "    url_refresh = 'https://api.projectcor.com/v1/oauth/refreshtoken'\n",
    "    content = {\n",
    "        \"refresh_token\": refresh_token\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url_refresh, json=content)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        new_token = response_json.get('token', {}).get('access_token')\n",
    "        if new_token:\n",
    "            print(\"Novo token gerado com sucesso.\")\n",
    "            return new_token\n",
    "        else:\n",
    "            print(\"Erro ao obter novo token.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Erro ao renovar o token: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def make_authenticated_request(url, token, refresh_token):\n",
    "    headers = {'Authorization': f'Bearer {token}'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 401:  # Token expirou\n",
    "        print(\"Token expirado, tentando renovar...\")\n",
    "        new_token = refresh_access_token(refresh_token)\n",
    "        if new_token:\n",
    "            headers['Authorization'] = f'Bearer {new_token}'\n",
    "            response = requests.get(url, headers=headers)  # Tenta novamente com o novo token\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"Requisição bem-sucedida!\")\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Erro na requisição: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Exemplo de uso:\n",
    "token, refresh_token = login()\n",
    "\n",
    "if token and refresh_token:\n",
    "    url_api = 'https://api.projectcor.com/v1/clients'\n",
    "    data = make_authenticated_request(url_api, token, refresh_token)\n",
    "    if data:\n",
    "        print(\"Dados obtidos:\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xUoCgxBcClz",
    "outputId": "b6a7c797-ba91-41be-f4c6-b8efffb10875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao criar o dataset: 409 POST https://bigquery.googleapis.com/bigquery/v2/projects/soulcode-434516/datasets?prettyPrint=false: Already Exists: Dataset soulcode-434516:projeto_final\n"
     ]
    }
   ],
   "source": [
    "project_id = 'soulcode-434516'\n",
    "dataset_id = 'projeto_final'\n",
    "location = 'US'\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "def create_dataset_bigQuery(client, dataset_id, location='US'):\n",
    "    \"\"\"Cria um dataset no BigQuery.\n",
    "\n",
    "    Args:\n",
    "        client: Um objeto cliente do BigQuery.\n",
    "        dataset_id: O ID do dataset a ser criado.\n",
    "        location: A localização geográfica do dataset.\n",
    "\n",
    "    Returns:\n",
    "        Um objeto Dataset representando o dataset criado.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Se ocorrer algum erro durante a criação do dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_ref = client.dataset(dataset_id)\n",
    "    dataset = bigquery.Dataset(dataset_ref)\n",
    "    dataset.location = location\n",
    "\n",
    "    try:\n",
    "        dataset = client.create_dataset(dataset)\n",
    "        print(f\"Dataset {dataset.dataset_id} criado com sucesso!\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "\n",
    "# auth.authenticate_user()\n",
    "\n",
    "# Criar o Dataset\n",
    "dataset = None\n",
    "try:\n",
    "    dataset = create_dataset_bigQuery(client, dataset_id, location)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar o dataset: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8LBnx8vddXLJ"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "def load_df_to_bigquery(df, project_id, dataset_id, table_id):\n",
    "  \"\"\"Loads a Pandas DataFrame into a BigQuery table.\n",
    "\n",
    "  Args:\n",
    "    df: The Pandas DataFrame to load.\n",
    "    project_id: Your Google Cloud project ID.\n",
    "    dataset_id: The BigQuery dataset ID.\n",
    "    table_id: The BigQuery table ID.\n",
    "  \"\"\"\n",
    "  # Construct the full table ID\n",
    "  table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "  # Configure the load job to truncate the table\n",
    "  job_config = bigquery.LoadJobConfig(\n",
    "      write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "  )\n",
    "\n",
    "  # Create a BigQuery client\n",
    "  client = bigquery.Client(project=project_id)\n",
    "\n",
    "  # Load the DataFrame into BigQuery\n",
    "  job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
    "  job.result()  # Wait for the job to complete\n",
    "\n",
    "  print(f\"DataFrame loaded to BigQuery table: {table_ref}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint Auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token de acesso: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1aWQiOjYyODQ3LCJkYXRhIjp7InVzZXJfaGFzaCI6ImM4YWI5OGQ1ZTAzYWExYWQzMTRkMjBmNDAxNzU4MTgwIiwiaXNfY29udGFjdCI6ZmFsc2UsImVudiI6InByb2R1Y3Rpb24ifSwiaWF0IjoxNzMwMDc5NTU3LCJleHAiOjE3MzAwODMxNTcsImF1ZCI6IkNPUjpBUElTRVJWSUNFUyJ9.Hq2wY37UnuL0dwI-VzQVwr3QaIopaAVdNCWPJkaxvNQ\n",
      "Token de atualização: 189c1b4197b69b00add6f2a2f6cc9302NlQhxmxbJpxzzY16QAGMAlcxjOI7PY7UgOSO6/5Hu51hq/aZI/Lk4qSH16FeKnkq\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def obter_tokens(url_login, email, senha):\n",
    "\n",
    "  dados = {\n",
    "      \"email\": email,\n",
    "      \"password\": senha\n",
    "  }\n",
    "\n",
    "  try:\n",
    "      resposta = requests.post(url_login, json=dados)\n",
    "      resposta.raise_for_status()\n",
    "      return resposta.json()['token']\n",
    "  except requests.exceptions.RequestException as e:\n",
    "      print(f\"Erro ao obter os tokens: {e}\")\n",
    "      return None\n",
    "\n",
    "\n",
    "url = \"https://api.projectcor.com/v1/auth/login\"\n",
    "email = \"academico@soulcode.com\"\n",
    "senha = \"Admin@123\"\n",
    "\n",
    "tokens = obter_tokens(url, email, senha)\n",
    "if tokens:\n",
    "  token_acesso = tokens['access_token']\n",
    "  token_atualizacao = tokens['refreshToken']\n",
    "  print(\"Token de acesso:\", token_acesso)\n",
    "  print(\"Token de atualização:\", token_atualizacao)\n",
    "else:\n",
    "  print(\"Falha ao obter os tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "kIaLYOls5LFa",
    "outputId": "c31d91ee-0ebd-4043-816c-17907e5b8889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1aWQiOjYyODQ3LCJkYXRhIjp7InVzZXJfaGFzaCI6ImM4YWI5OGQ1ZTAzYWExYWQzMTRkMjBmNDAxNzU4MTgwIiwiaXNfY29udGFjdCI6ZmFsc2UsImVudiI6InByb2R1Y3Rpb24ifSwiaWF0IjoxNzMwMDg2NDg2LCJleHAiOjE3MzAwOTAwODYsImF1ZCI6IkNPUjpBUElTRVJWSUNFUyJ9.nqRzJtS2GNGix_hRCD-ZTzbzWGbdRKSFTEIyUGuMtS8\n",
      "--------------------------------------------------------------------------------\n",
      "7afddb7e6efd3a27621cdc1270193017qXEO08TtTGNA8NxbpZIdIUusnr3A9WS5EDDkhe+yFYWszMOScbDpo71HtVEn7X+U\n"
     ]
    }
   ],
   "source": [
    "url_login = 'https://api.projectcor.com/v1/auth/login'\n",
    "content = {\n",
    "  \"email\": \"academico@soulcode.com\",\n",
    "  \"password\": \"Admin@123\"\n",
    "}\n",
    "response  = requests.post(url_login, json=content)\n",
    "\n",
    "\n",
    "token = response.json()['token']['access_token']\n",
    "refresh_token = response.json()['token']['refreshToken']\n",
    "print(token)\n",
    "print(80 * '-')\n",
    "print(refresh_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59xlUSHnBRgB"
   },
   "source": [
    "# Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qs0iACd3-TlK",
    "outputId": "acf53d9c-46cb-4a63-bb75-8f0cd9743d6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://api.projectcor.com/v1'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {token}',\n",
    "    'Content-Type': \"application/json\"\n",
    "}\n",
    "url = base_url + '/clients'\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "cBwQAyst4q1s",
    "outputId": "d4e36ba3-83d0-4b6b-b670-b888b8d1342c"
   },
   "outputs": [],
   "source": [
    "# horas\n",
    "base_url = \"https://api.projectcor.com/v1\"\n",
    "endpoint = 'https://api.projectcor.com/v1/hours?filters={\"dateStart\":\"2024-01-01\",\"dateDeadline\":\"2024-10-22\",\"clients\":null,\"projects\":null,\"users\":null,\"labels\":null,\"teams\":null }&page=1&orderBy={\"by\":\"start\",\"order\":\"ASC\"}'\n",
    "page = 1\n",
    "query =  f'https://api.projectcor.com/v1/hours?filters={{\"dateStart\":\"2024-10-03\",\"dateDeadline\":\"2024-10-03\",\"clients\":null,\"projects\":null,\"users\":null,\"labels\":null,\"teams\":null}}&page={page}&orderBy={{\"by\":\"start\",\"order\":\"ASC\"}}'\n",
    "\n",
    "\n",
    "data = fetch_data_with_retry(query, headers=headers, max_retries=3, retry_delay=3)\n",
    "df = pd.DataFrame(data['data'])\n",
    "df_info = pd.DataFrame(data)\n",
    "display(int(df_info['lastPage'][0]))\n",
    "# lastpage = df_info['last_page']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endopoint /hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NFSuJfRRZ8i"
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "page = 1\n",
    "while page <= 10: #4078\n",
    "    query =  f'https://api.projectcor.com/v1/hours?filters={{\"dateStart\":\"2024-10-01\",\"dateDeadline\":\"2024-10-17\",\"clients\":null,\"projects\":null,\"users\":null,\"labels\":null,\"teams\":null}}&page={page}&orderBy={{\"by\":\"start\",\"order\":\"ASC\"}}'\n",
    "    data = fetch_data_with_retry(query, headers=headers, max_retries=5, retry_delay=3)\n",
    "\n",
    "    if data is None or not data['data']:\n",
    "        break\n",
    "\n",
    "    all_data.extend(data['data'])\n",
    "    page = page + 1\n",
    "    print(page, end=', ')\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_df_to_bigquery(df,project_id=project_id, dataset_id=dataset_id,table_id=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcku4cvi82Ea"
   },
   "outputs": [],
   "source": [
    "# df_page_1 = pd.DataFrame(data)\n",
    "# df_page_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dia da requisição: 2024-01-01: 8\n",
      "Dia da requisição: 2024-01-02: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import calendar\n",
    "\n",
    "\n",
    "start_year = 2024  # Adjust for starting year if needed\n",
    "start_month = 1\n",
    "current_month = date.today().month  # Get current month\n",
    "\n",
    "today = date.today()\n",
    "all_data = []\n",
    "\n",
    "for month in range(start_month, current_month + 1):\n",
    "    days_in_month = calendar.monthrange(start_year, month)[1]\n",
    "    \n",
    "    for day in range(1, days_in_month + 1):\n",
    "        current_date = date(year=start_year, month=month, day=day)\n",
    "        print(f'Dia da requisição: {current_date}', end=': ')\n",
    "\n",
    "        if current_date > today:\n",
    "            break  # Stop iterating if date is in the future\n",
    "\n",
    "        formatted_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "        page = 1\n",
    "        \n",
    "        token, refresh_token = login()\n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {token}',\n",
    "            'Content-Type': \"application/json\"\n",
    "        }\n",
    "        while token and refresh_token:\n",
    "            next_page_query = f'https://api.projectcor.com/v1/hours?filters={{\"dateStart\":\"{formatted_date}\",\"dateDeadline\":\"{formatted_date}\",\"clients\":null,\"projects\":null,\"users\":null,\"labels\":null,\"teams\":null}}&page={page}&orderBy={{\"by\":\"start\",\"order\":\"ASC\"}}'\n",
    "            next_page_data = fetch_data_with_retry(next_page_query, headers,max_retries=5, retry_delay=3)\n",
    "            # next_page_data = make_authenticated_request(next_page_query,token=token,refresh_token=refresh_access_token)\n",
    "\n",
    "\n",
    "            if next_page_data is None or not next_page_data['data']:\n",
    "                break\n",
    "\n",
    "            all_data.extend(next_page_data['data'])\n",
    "            page += 1\n",
    "        print(page, end='\\n')\n",
    "\n",
    "        \n",
    "\n",
    "print(\"Data fetching complete.\")\n",
    "\n",
    "# Create pandas DataFrame if data is available and not empty\n",
    "if all_data:\n",
    "    df_daily = pd.DataFrame(all_data)\n",
    "    print(\"Dataframe created successfully.\")\n",
    "else:\n",
    "    print(\"No data retrieved. Dataframe creation skipped.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_daily.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gylhxtEA4YnS"
   },
   "outputs": [],
   "source": [
    "df_ = df_daily.drop(columns=['?column?'])\n",
    "load_df_to_bigquery(df_,project_id=project_id, dataset_id=dataset_id,table_id=\"df_threemonth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3U7uphmWjM5s"
   },
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# start_year = 2024\n",
    "# start_month = 1  # Adjust this to your desired starting month (1-12)\n",
    "\n",
    "# today = datetime.date.today()\n",
    "# end_day = today.day\n",
    "# all_data = []\n",
    "\n",
    "# for day in range(1, end_day + 1):\n",
    "#     date = datetime.date(year=start_year, month=start_month, day=day)\n",
    "#     print(f'Dia da requisição:{date}', end=': ')\n",
    "#     # Check if the current date is after the desired start month\n",
    "#     if date > today:\n",
    "#         break\n",
    "    \n",
    "#     formatted_date = date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "#     # last_page = int(data_info['lastPage'][0])\n",
    "#     page = 1\n",
    "#     while True:\n",
    "        \n",
    "#         next_page_query = f'https://api.projectcor.com/v1/hours?filters={{\"dateStart\":\"{formatted_date}\",\"dateDeadline\":\"{formatted_date}\",\"clients\":null,\"projects\":null,\"users\":null,\"labels\":null,\"teams\":null}}&page={page}&orderBy={{\"by\":\"start\",\"order\":\"ASC\"}}'\n",
    "#         next_page_data = fetch_data_with_retry(next_page_query, headers, max_retries=5, retry_delay=600)\n",
    "        \n",
    "#         if next_page_data is None or not next_page_data['data']:\n",
    "#             break\n",
    "\n",
    "#         all_data.extend(data['data'])\n",
    "#         page += 1\n",
    "#     print(page, end='\\n')\n",
    "\n",
    "# print('Data fetching complete')\n",
    "\n",
    "# df_daily = pd.DataFrame(all_data)\n",
    "\n",
    "    # Process the daily DataFrame as needed (e.g., save, append, etc.)\n",
    "    # ...\n",
    "\n",
    "# Combine or process all daily DataFrames as needed (optional)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNad8u0xaETV"
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4lp9u5khzqN"
   },
   "outputs": [],
   "source": [
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eojlSgbchzW2"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rework_hour'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmipGvCZTJBh"
   },
   "outputs": [],
   "source": [
    "df['duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPiBWsXN2tCa"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g73LZPnHdv3D"
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['?column?', 'cost','project_id', 'client_id','comments', 'client', 'project','userPosition', 'billInput']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df_to_bigquery(df,project_id=project_id, dataset_id=dataset_id,table_id=\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4QSx4p5gRHm"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTah_s-cpKI3"
   },
   "outputs": [],
   "source": [
    "df_hours = df.iloc[:,:10]\n",
    "df_hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NgSEyxN_X5ca"
   },
   "outputs": [],
   "source": [
    "df_hours.rename(columns={'id': 'id_hours'}, inplace=True)\n",
    "df_hours.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hours.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gylhxtEA4YnS"
   },
   "outputs": [],
   "source": [
    "load_df_to_bigquery(df_hours,project_id=project_id, dataset_id=dataset_id,table_id=\"hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEspLvIjpZst"
   },
   "outputs": [],
   "source": [
    "df_users = df[['user']]\n",
    "user_list = []\n",
    "for index, row in df_users.iterrows():\n",
    "    user_list.append(row['user'])\n",
    "df_users = pd.DataFrame(user_list)\n",
    "df_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrphRt9iYPH5"
   },
   "outputs": [],
   "source": [
    "df_users.rename(columns={'id': 'id_user'}, inplace=True)\n",
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_users.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDpICB2_7O04"
   },
   "outputs": [],
   "source": [
    "load_df_to_bigquery(df_users,project_id=project_id, dataset_id=dataset_id,table_id=\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vj5_ucCe78JS"
   },
   "outputs": [],
   "source": [
    "# df_hours_user = pd.merge(df_hours, df_users, left_on='user_id', right_on='id_user')\n",
    "# display(df_hours_user)\n",
    "# load_df_to_bigquery(df_hours_user,project_id=project_id, dataset_id=dataset_id,table_id=\"users_hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HivMDHWytFNx"
   },
   "outputs": [],
   "source": [
    "df_tasks = df[['task']]\n",
    "\n",
    "task_list = []\n",
    "for index, row in df_tasks.iterrows():\n",
    "    task_list.append(row['task'])\n",
    "\n",
    "\n",
    "df_tasks = pd.DataFrame(task_list)\n",
    "df_project = df_tasks[['project']]\n",
    "\n",
    "# drop_columns_task = ['task_father', 'father', 'labels', 'reworks', 'lastReworks','project']\n",
    "# df_tasks = df_tasks.drop(columns=drop_columns_task)\n",
    "df_tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYfBVR8PaiKG"
   },
   "outputs": [],
   "source": [
    "df_tasks.rename(columns={'id': 'task_id'}, inplace=True)\n",
    "df_tasks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tasks.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df_to_bigquery(df_tasks,project_id=project_id, dataset_id=dataset_id,table_id=\"task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe reworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df_tasks['reworks'] = df_tasks['reworks'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "df_tasks['lastReworks'] = df_tasks['lastReworks'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "filtered_data = df_tasks[(df_tasks['reworks'].apply(lambda x: len(x) > 0)) | (df_tasks['lastReworks'].apply(lambda x: len(x) > 0))]\n",
    "filtered_data[['reworks', 'lastReworks']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reworks = filtered_data[['reworks']]\n",
    "\n",
    "reworks_list = []\n",
    "for index, row in filtered_data.iterrows():\n",
    "    for x in row['reworks']:\n",
    "        field_change = x['field_change']\n",
    "        del x['field_change']\n",
    "        dict_concat = {**x, **field_change}\n",
    "        reworks_list.append(dict_concat)\n",
    "\n",
    "df_reworks = pd.DataFrame(reworks_list)\n",
    "df_reworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df_to_bigquery(df_reworks,project_id=project_id, dataset_id=dataset_id,table_id=\"reworks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Last Reworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lastreworks = filtered_data[['lastReworks']]\n",
    "\n",
    "lastreworks_list = []\n",
    "for index, row in filtered_data.iterrows():\n",
    "    for x in row['lastReworks']:\n",
    "        lastreworks_list.append(x)\n",
    "        \n",
    "df_lastreworks = pd.DataFrame(lastreworks_list)\n",
    "df_lastreworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df_to_bigquery(df_lastreworks,project_id=project_id, dataset_id=dataset_id,table_id=\"lastreworks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKP6cjBXAf_r"
   },
   "outputs": [],
   "source": [
    "df_project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Q2RWg5Gt3wH"
   },
   "outputs": [],
   "source": [
    "project_list = []\n",
    "for index, row in df_project.iterrows():\n",
    "    project_list.append(row['project'])\n",
    "\n",
    "df_project = pd.DataFrame(project_list)\n",
    "df_client = df_project[['client']]\n",
    "\n",
    "df_project = df_project.drop(columns=['client'])\n",
    "df_project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_project.rename(columns={'id': 'project_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df_to_bigquery(df_project,project_id=project_id, dataset_id=dataset_id,table_id=\"project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJPFdXHUvX-4"
   },
   "outputs": [],
   "source": [
    "client_list = []\n",
    "for index, row in df_client.iterrows():\n",
    "    client_list.append(row['client'])\n",
    "\n",
    "df_client = pd.DataFrame(client_list)\n",
    "df_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client.rename(columns={'id': 'client_id', 'name':'nama_client'}, inplace=True)\n",
    "df_client.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df_to_bigquery(df_client,project_id=project_id, dataset_id=dataset_id,table_id=\"client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gZ59XVT56qS"
   },
   "outputs": [],
   "source": [
    "df_client.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df_users.copy()  # Replace with your data loading method\n",
    "hours = df_hours.copy()\n",
    "task = df_tasks.copy()\n",
    "project = df_project.copy()\n",
    "client = df_client.copy()\n",
    "\n",
    "users_hours_merge_key = \"id_user\"  # Assuming users.id_user is the same as hours.user_id\n",
    "hours_task_merge_key = \"task_log_id\"  # Assuming hours.task_log_id is the same as task.task_id\n",
    "task_project_merge_key = \"project_id\"\n",
    "project_client_merge_key = \"client_id\"\n",
    "\n",
    "joined_data = pd.merge(users, hours, left_on='id_user', right_on='user_id')\n",
    "joined_data = pd.merge(joined_data, task, left_on='task_log_id', right_on='task_id')\n",
    "joined_data = pd.merge(joined_data, project, left_on='project_id', right_on='project_id')\n",
    "joined_data = pd.merge(joined_data, project, left_on='client_id', right_on='client_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# selected_columns = {\n",
    "#     \"id_user\": \"users_id_user\",\n",
    "#     \"first_name\": \"users_first_name\",\n",
    "#     \"last_name\": \"users_last_name\",\n",
    "#     \"id_hours\": \"hours_id_hours\",\n",
    "#     \"start\": \"hours_start\",\n",
    "#     \"stop\": \"hours_stop\",\n",
    "#     \"duration\": \"hours_duration\",\n",
    "#     \"task_id\": \"task_task_id\",\n",
    "#     \"title\": \"task_title\",\n",
    "#     \"project_id\": \"project_project_id\",\n",
    "#     \"name_x\": \"project_name\",\n",
    "#     \"client_id\": \"client_client_id\",\n",
    "#     \"name_y\": \"client_name\",  }\n",
    "\n",
    "\n",
    "# joined_data.rename(columns=selected_columns, inplace=True)\n",
    "\n",
    "joined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OH4O4FACiVQ"
   },
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df_hours, df_users,df_tasks,df_project,df_client], axis=1)\n",
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint Contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_contacts = 'https://api.projectcor.com/v1/contacts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NFSuJfRRZ8i"
   },
   "outputs": [],
   "source": [
    "data_contacts = []\n",
    "page = 1\n",
    "\n",
    "query =  f'https://api.projectcor.com/v1/contacts?filters={{\"dateStart\":\"2024-10-01\",\"dateDeadline\":\"2024-10-17\",\"clients\":null,\"projects\":null,\"users\":null,\"labels\":null,\"teams\":null}}&page={page}&orderBy={{\"by\":\"start\",\"order\":\"ASC\"}}'\n",
    "data = fetch_data_with_retry(query, headers=headers, max_retries=3, retry_delay=3)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_clients = 'https://api.projectcor.com/v1/clients'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NFSuJfRRZ8i"
   },
   "outputs": [],
   "source": [
    "data_contacts = []\n",
    "page = 1\n",
    "data = fetch_data_with_retry(end_clients, headers=headers, max_retries=3, retry_delay=3)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_projects = 'https://api.projectcor.com/v1/projects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_contacts = []\n",
    "page = 1\n",
    "query = f'https://api.projectcor.com/v1/projects?filters={{\"dateStart\": \"2024-10-01\", \"dateEnd\": \"2024-10-17\", \"client_id\": null, \"team_id\": null, \"status\": [\"finished\", \"in_process\", \"suspended\"], \"user_id\": null, \"health\": [1, 2, 3, 4], \"brand_id\": null, \"archived\": [1, 2], \"product_id\": null}}&page={page}&orderBy={{\"by\": \"start\", \"order\": \"ASC\"}}'\n",
    "data = fetch_data_with_retry(end_projects, headers=headers, max_retries=3, retry_delay=3)\n",
    "df = pd.DataFrame(data)\n",
    "print(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_brands = 'https://api.projectcor.com/v1/brands'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_contacts = []\n",
    "page = 1\n",
    "data = fetch_data_with_retry(end_brands, headers=headers, max_retries=3, retry_delay=3)\n",
    "df = pd.DataFrame(data)\n",
    "print(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_products = 'https://api.projectcor.com/v1/products'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_contacts = []\n",
    "page = 1\n",
    "data = fetch_data_with_retry(end_products, headers=headers, max_retries=3, retry_delay=3)\n",
    "df = pd.DataFrame(data)\n",
    "print(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_task = 'https://api.projectcor.com/v1/tasks?page=1&perPage=20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_contacts = []\n",
    "page = 1\n",
    "data = fetch_data_with_retry(end_task, headers=headers, max_retries=3, retry_delay=3)\n",
    "df = pd.DataFrame(data)\n",
    "print(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_user = 'https://api.projectcor.com/v1/users/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_contacts = []\n",
    "page = 1\n",
    "data = fetch_data_with_retry(end_user, headers=headers, max_retries=3, retry_delay=3)\n",
    "df = pd.DataFrame(data)\n",
    "print(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_transactions = 'https://api.projectcor.com/v1/transactions/total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_data_with_retry(end_transactions, headers=headers, max_retries=3, retry_delay=3)\n",
    "df = pd.DataFrame(data)\n",
    "print(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
