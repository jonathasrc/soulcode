{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EGyu5nGlPxS"
      },
      "source": [
        "1. Análise de Consistência de Dados: Identificar e corrigir inconsistências nos valores de \"Área\" e \"Status de Emprego\" (e.g., diferenças de maiúsculas/minúsculas).\n",
        "2. Limpeza de Dados Faltantes: Detectar e tratar os valores ausentes na coluna \"Idade\" e \"Área\".\n",
        "3. Distribuição de Idade: Analisar a distribuição da idade dos funcionários por departamento.\n",
        "4. Salário por Departamento: Calcular a média, mediana e desvio padrão dos salários por departamento.\n",
        "5. Análise de Outliers: Identificar salários que estão fora do padrão (outliers) para cada departamento.\n",
        "6. Correlação Idade-Salário: Analisar a correlação entre idade e salário dos funcionários.\n",
        "7. Tempo de Casa: Calcular o tempo de contratação dos funcionários e categorizá-los em grupos (e.g., 1-3 anos, 4-6 anos, etc.).\n",
        "8. Análise de Rotatividade: Identificar padrões entre os funcionários que estão ativos versus os que não estão.\n",
        "9. Análise de Desempenho por Data de Contratação: Verificar se existe uma correlação entre o ano de contratação e o nível de salário.\n",
        "10. Histograma de Salário: Criar um histograma de salários para visualizar a distribuição geral.\n",
        "11. Análise de Frequência: Quantificar a frequência dos nomes dos funcionários para identificar nomes comuns.\n",
        "12. Agrupamento de Departamentos: Analisar o impacto do departamento na variação salarial e na distribuição de idade.\n",
        "13. Normalização de Dados: Normalizar o salário e idade para comparações entre diferentes departamentos.\n",
        "14. Proporção de Gêneros: Analisar a proporção de gêneros entre os funcionários, caso houvesse uma coluna de gênero.\n",
        "15. Correção de Formato de Data: Uniformizar o formato das datas de contratação.\n",
        "16. Impacto de Status no Salário: Comparar salários médios entre funcionários ativos e não ativos.\n",
        "17. Data de Contratação e Demografia: Relacionar a data de contratação com a idade dos funcionários na época da contratação.\n",
        "18. Distribuição de Status de Emprego: Analisar a distribuição do status de emprego (ativo vs. não ativo).\n",
        "19. Criação de Coluna de Idade de Contratação: Criar uma coluna que calcule a idade do funcionário na época da contratação e analisar os dados.\n",
        "20. Análise de Promoções: Analisar possíveis promoções dentro da empresa ao comparar datas de contratação e aumentos salariais, se houvesse uma coluna histórica de salários.\n",
        "21. Análise de Desempenho Temporal: Verificar se o tempo de casa influencia o salário ou a permanência no emprego.\n",
        "22. Filtragem por Data de Contratação: Identificar funcionários contratados em períodos específicos (e.g., antes de 2019, entre 2019-2020).\n",
        "23. Análise de Status de Emprego e Tempo de Casa: Verificar a relação entre tempo de casa e status de emprego (ativo vs. não ativo).\n",
        "24. Identificação de Funcionários Veteranos: Encontrar os funcionários com maior tempo de casa e analisar seu impacto na empresa.\n",
        "25. Análise de Tendências de Contratação: Identificar padrões de contratação ao longo do tempo, como sazonalidade.\n",
        "26. Salário Máximo e Mínimo por Departamento: Determinar os salários mais altos e mais baixos dentro de cada departamento.\n",
        "27. Classificação de Funcionários por Salário: Criar rankings de funcionários por salário dentro de cada departamento.\n",
        "28. Projeção de Aposentadoria: Estimar o número de funcionários que podem se aposentar em breve com base na idade.\n",
        "29. Segmentação de Funcionários por Faixa Salarial: Agrupar funcionários em faixas salariais (e.g., 2000-3000, 3001-4000) e analisar a distribuição.\n",
        "30. Análise de Equidade Salarial: Verificar se há desigualdade salarial dentro de departamentos específicos.\n",
        "31. Comparação de Salários por Período de Contratação: Comparar os salários de funcionários contratados em diferentes anos para identificar tendências de aumento salarial.\n",
        "32. Criação de Coluna de Faixa Etária: Agrupar os funcionários em faixas etárias (e.g., 20-30 anos, 31-40 anos) e analisar diferenças entre elas.\n",
        "33. Relação Entre Área e Tempo de Contratação: Identificar se alguns departamentos tendem a manter seus funcionários por mais tempo do que outros.\n",
        "34. Previsão de Turnover: Usar dados históricos para prever quais funcionários têm maior probabilidade de deixar a empresa.\n",
        "35. Análise de Homogeneidade Salarial: Verificar a homogeneidade dos salários dentro de cada departamento.\n",
        "36. Detecção de Funcionários Com Anomalias: Identificar funcionários com salários e idades que destoam significativamente dos outros no mesmo departamento.\n",
        "37. Comparação de Salários por Região: Se houvesse uma coluna de localização, comparar os salários entre diferentes regiões.\n",
        "38. Criação de Métricas Personalizadas: Desenvolver novas métricas como \"salário ajustado pela idade\" ou \"tempo de casa ajustado pela idade\".\n",
        "39. Análise de Recrutamento Recente: Focar na análise dos funcionários contratados nos últimos 12 meses para ver tendências.\n",
        "40. Distribuição de Funcionários por Departamento: Quantificar o número de funcionários por departamento e comparar com a média salarial.\n",
        "41. Análise de Rotatividade por Departamento: Verificar se há departamentos com alta rotatividade de funcionários.\n",
        "42. Comparação de Salários por Gênero: Se houvesse uma coluna de gênero, comparar os salários médios entre homens e mulheres.\n",
        "43. Correlação Entre Status de Emprego e Desempenho Salarial: Avaliar se há diferença significativa de salários entre diferentes status de emprego.\n",
        "44. Análise de Impacto de Promoções: Se houvesse dados de promoções, analisar o impacto das promoções no salário ao longo do tempo.\n",
        "45. Projeção de Custos Salariais: Calcular o custo projetado para a empresa em termos de salários nos próximos anos.\n",
        "46. Análise de Desempenho por Escolaridade: Se houvesse uma coluna de escolaridade, analisar o impacto da escolaridade no salário.\n",
        "47. Comparação Entre Funcionários com Benefícios: Se houvesse dados de benefícios, comparar o salário entre funcionários que recebem ou não benefícios.\n",
        "48. Análise de Desempenho por Formação Acadêmica: Se houvesse uma coluna de formação, analisar como diferentes formações afetam o salário e tempo de casa.\n",
        "49. Previsão de Salários Futuros: Usar regressão linear ou outros modelos para prever o crescimento salarial futuro.\n",
        "50. Identificação de Padrões de Promoção Interna: Analisar os padrões de promoção dentro da empresa ao longo dos anos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "BxBdbqt9uCmr",
        "outputId": "76e17857-f9f9-4a6f-8e4f-41ffcf51a52c"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql.functions import col, round, avg, min, max, stddev, regexp_replace\n",
        "from pyspark.sql.types import DoubleType\n",
        "from unidecode import unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJthmuWWtYca"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "PGL09dhZtXCl"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import initcap\n",
        "\n",
        "def clean_column_names(df):\n",
        "\n",
        "    if isinstance(df, DataFrame):\n",
        "      for col in df.columns:\n",
        "        df = df.withColumnRenamed(col, unidecode(col.lower().replace(' ', '_')))\n",
        "    else:\n",
        "      for col in df.columns:\n",
        "        df.rename(columns={col:unidecode(col.lower().replace(' ', '_'))}, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "    \n",
        "def translate_first_letter_uppercase_df(df, subset=[]):\n",
        "    if not subset:\n",
        "        subset = df.columns\n",
        "    \n",
        "    for column in subset:\n",
        "        df = df.withColumn(column, initcap(column))\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "S4MgjgY3nr6g"
      },
      "outputs": [],
      "source": [
        "# Create a PySpark session\n",
        "spark = SparkSession.builder.appName(\"Atividade_04_pyspark\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "j5-P9vbmoxf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- nome: string (nullable = true)\n",
            " |-- idade: integer (nullable = true)\n",
            " |-- area: string (nullable = true)\n",
            " |-- salario: string (nullable = true)\n",
            " |-- data_de_contratacao: string (nullable = true)\n",
            " |-- status_de_emprego: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dir_dataset = '/home/jovyan/code/dataset/'\n",
        "dataset = 'base_suja.csv'\n",
        "\n",
        "df = spark.read.csv(dir_dataset + dataset, header=True, inferSchema=True)\n",
        "df = clean_column_names(df)\n",
        "df.printSchema()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEeT8a-qotDi"
      },
      "source": [
        "### 1. Análise de Consistência de Dados: Identificar e corrigir inconsistências nos valores de \"Área\" e \"Status de Emprego\" (e.g., diferenças de maiúsculas/minúsculas).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+--------------+-----+----------+-------+-------------------+-----------------+\n",
            "| id|          nome|idade|      area|salario|data_de_contratacao|status_de_emprego|\n",
            "+---+--------------+-----+----------+-------+-------------------+-----------------+\n",
            "|  1|    João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
            "|  2|   Maria Souza|   30|        Rh|   4800|         15-03-2019|            Ativo|\n",
            "|  3|Carlos Pereira| NULL| Finaceiro|   6200|         2020/04/01|            Ativo|\n",
            "|  4|     Ana Clara|   27| Marketing|   4800|         12/06/2018|            Ativo|\n",
            "|  5|  Fabio Santos|   31|      NULL|   5500|         20-11-2017|            Ativo|\n",
            "|  6|   Sandra Lima|   28|        Rh|   NULL|         05-05-2020|            Ativo|\n",
            "|  7|    José Alves|   34| Marketing|   5400|         2018/02/01|          Inativo|\n",
            "|  8| Luciana Costa|   30|Financeiro|R$ 5200|         01.01.2019|            Ativo|\n",
            "|  9| Paulo Ricardo| NULL| Finaceiro|   6100|         12/12/2020|          Inativo|\n",
            "| 10| Fernanda Dias|   29|        Rh|   4800|               NULL|            Ativo|\n",
            "|  1|    João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
            "+---+--------------+-----+----------+-------+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = translate_first_letter_uppercase_df(df,subset=['area','status_de_emprego'])\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Limpeza de Dados Faltantes: Detectar e tratar os valores ausentes na coluna \"Idade\" e \"Área\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
            "| id|         nome|idade|      area|salario|data_de_contratacao|status_de_emprego|\n",
            "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
            "|  1|   João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
            "|  2|  Maria Souza|   30|        Rh|   4800|         15-03-2019|            Ativo|\n",
            "|  4|    Ana Clara|   27| Marketing|   4800|         12/06/2018|            Ativo|\n",
            "|  7|   José Alves|   34| Marketing|   5400|         2018/02/01|          Inativo|\n",
            "|  8|Luciana Costa|   30|Financeiro|R$ 5200|         01.01.2019|            Ativo|\n",
            "|  1|   João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
            "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.na.drop(how='any', subset=[]) ## list com nomes das colunas\n",
        "df = df.na.drop(how='any') # any | all | thresh \n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Distribuição de Idade: Analisar a distribuição da idade dos funcionários por departamento.3. Distribuição de Idade: Analisar a distribuição da idade dos funcionários por departamento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+\n",
            "|summary|idade|\n",
            "+-------+-----+\n",
            "|  count|  6.0|\n",
            "|   mean|29.83|\n",
            "| stddev| 2.32|\n",
            "|    min| 27.0|\n",
            "|    25%| 29.0|\n",
            "|    50%| 29.0|\n",
            "|    75%| 30.0|\n",
            "|    max| 34.0|\n",
            "+-------+-----+\n",
            "\n",
            "Analise de distribuição do Rh\n",
            "+-------+-----+\n",
            "|summary|idade|\n",
            "+-------+-----+\n",
            "|  count|  1.0|\n",
            "|   mean| 30.0|\n",
            "| stddev| NULL|\n",
            "|    min| 30.0|\n",
            "|    25%| 30.0|\n",
            "|    50%| 30.0|\n",
            "|    75%| 30.0|\n",
            "|    max| 30.0|\n",
            "+-------+-----+\n",
            "\n",
            "Analise de distribuição do Financeiro\n",
            "+-------+-----+\n",
            "|summary|idade|\n",
            "+-------+-----+\n",
            "|  count|  3.0|\n",
            "|   mean| 29.0|\n",
            "| stddev|  1.0|\n",
            "|    min| 29.0|\n",
            "|    25%| 29.0|\n",
            "|    50%| 29.0|\n",
            "|    75%| 30.0|\n",
            "|    max| 30.0|\n",
            "+-------+-----+\n",
            "\n",
            "Analise de distribuição do Marketing\n",
            "+-------+-----+\n",
            "|summary|idade|\n",
            "+-------+-----+\n",
            "|  count|  2.0|\n",
            "|   mean| 31.0|\n",
            "| stddev|  5.0|\n",
            "|    min| 27.0|\n",
            "|    25%| 27.0|\n",
            "|    50%| 27.0|\n",
            "|    75%| 34.0|\n",
            "|    max| 34.0|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_age_departament = df.select('idade','area')\n",
        "departaments = df_age_departament.select('area').distinct().collect()\n",
        "departaments = [row['area'] for row in departaments]\n",
        "\n",
        "df_age_departament.select('idade').summary() \\\n",
        "    .withColumn('idade', round(col('idade'), 2)) \\\n",
        "        .show() # alternativo para describe()\n",
        "\n",
        "for departament in departaments:\n",
        "    print(f'Analise de distribuição do {departament}')\n",
        "    df_age_departament.filter(df_age_departament.area == departament)\\\n",
        "        .select('idade')\\\n",
        "        .summary()\\\n",
        "        .withColumn('idade', round(col('idade')))\\\n",
        "        .show()\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Salário por Departamento: Calcular a média, mediana e desvio padrão dos salários por departamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+\n",
            "|salario|      area|\n",
            "+-------+----------+\n",
            "|   5500|Financeiro|\n",
            "|   4800|        Rh|\n",
            "|   4800| Marketing|\n",
            "|   5400| Marketing|\n",
            "|R$ 5200|Financeiro|\n",
            "|   5500|Financeiro|\n",
            "+-------+----------+\n",
            "\n",
            "root\n",
            " |-- salario: string (nullable = true)\n",
            " |-- area: string (nullable = true)\n",
            "\n",
            "Estasticas dos departamentos: Rh\n",
            "+----+-------------+--------------+--------------+---------------------+\n",
            "|area|media_salario|salario_minimo|salario_maximo|desvio_padrao_salario|\n",
            "+----+-------------+--------------+--------------+---------------------+\n",
            "|  Rh|       4800.0|        4800.0|        4800.0|                 NULL|\n",
            "+----+-------------+--------------+--------------+---------------------+\n",
            "\n",
            "Estasticas dos departamentos: Financeiro\n",
            "+----------+-------------+--------------+--------------+---------------------+\n",
            "|      area|media_salario|salario_minimo|salario_maximo|desvio_padrao_salario|\n",
            "+----------+-------------+--------------+--------------+---------------------+\n",
            "|Financeiro|       5400.0|        5200.0|        5500.0|                173.0|\n",
            "+----------+-------------+--------------+--------------+---------------------+\n",
            "\n",
            "Estasticas dos departamentos: Marketing\n",
            "+---------+-------------+--------------+--------------+---------------------+\n",
            "|     area|media_salario|salario_minimo|salario_maximo|desvio_padrao_salario|\n",
            "+---------+-------------+--------------+--------------+---------------------+\n",
            "|Marketing|       5100.0|        4800.0|        5400.0|                424.0|\n",
            "+---------+-------------+--------------+--------------+---------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "df_salary_departament = df.select('salario', 'area')\n",
        "df_salary_departament.show()\n",
        "df_salary_departament.printSchema()\n",
        "\n",
        "df_salary_departament = df_salary_departament.withColumn('salario', regexp_replace(col('salario'),\"R\\\\$\",\"\" ))\\\n",
        "    .withColumn('salario',col('salario').cast(DoubleType()))\n",
        "\n",
        "for departament in departaments:\n",
        "    print(f'Estasticas dos departamentos: {departament}')    \n",
        "    df_stats = df_salary_departament \\\n",
        "        .groupBy('area') \\\n",
        "        .agg(\n",
        "            round(avg('salario')).alias('media_salario'),\n",
        "            min('salario').alias('salario_minimo'),\n",
        "            max('salario').alias('salario_maximo'),\n",
        "            round(stddev('salario')).alias('desvio_padrao_salario')\n",
        "        ).filter(col('area') == departament) \\\n",
        "        .show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Análise de Outliers: Identificar salários que estão fora do padrão (outliers) para cada departamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Referencias\n",
        "\n",
        "- https://colab.research.google.com/drive/10EufW2wlVEy3NJZtkDa6h6cyhWjP2TfD?usp=sharing#scrollTo=2jrxJJzHcHX2 (Professor: Adriano Gomes) \n",
        "\n",
        "- https://www.analyticsvidhya.com/blog/2022/05/data-preprocessing-using-pyspark-handling-missing-values/ (limpeza de dados)\n",
        "- https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.initcap.html "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kZAzBjT-1Wv"
      },
      "source": [
        "## 4. Elabore Análises com filtros e agrupamentos aprendidos em PySpark na aula de ontem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Ckt6Ugxu_PjC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 7)\n"
          ]
        }
      ],
      "source": [
        "# shape da matriz\n",
        "print((df.count(), len(df.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "5JwCN3NC_a0C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+----+-------+-------------------+-----------------+\n",
            "| id|nome|idade|area|salario|data_de_contratacao|status_de_emprego|\n",
            "+---+----+-----+----+-------+-------------------+-----------------+\n",
            "+---+----+-----+----+-------+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.sample(False,0.1).show(1) #(probabilidade vazio, chance de ser sorteado novamente)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Ea9gmzhM_6wL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Row(_1=Row(id=1, nome='João Silva', idade=29, area='Financeiro', salario='5500', data_de_contratacao='01/02/2020', status_de_emprego='Ativo'), _2=0)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tmp = df.rdd.map(lambda row:row).zipWithIndex().toDF()\n",
        "\n",
        "df_tmp.first() # primeira linha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIp3KLdxC1I1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "203pOjmEsPGj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- nome: string (nullable = true)\n",
            " |-- idade: integer (nullable = true)\n",
            " |-- area: string (nullable = true)\n",
            " |-- salario: string (nullable = true)\n",
            " |-- data_de_contratacao: string (nullable = true)\n",
            " |-- status_de_emprego: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "pgcvKGyrsBpW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------------+-----------+------------------+----------+------------------+-------------------+-----------------+\n",
            "|summary|                id|       nome|             idade|      area|           salario|data_de_contratacao|status_de_emprego|\n",
            "+-------+------------------+-----------+------------------+----------+------------------+-------------------+-----------------+\n",
            "|  count|                 6|          6|                 6|         6|                 6|                  6|                6|\n",
            "|   mean|3.8333333333333335|       NULL|29.833333333333332|      NULL|            5200.0|               NULL|             NULL|\n",
            "| stddev| 3.060501048303474|       NULL|2.3166067138525404|      NULL|367.42346141747674|               NULL|             NULL|\n",
            "|    min|                 1|  Ana Clara|                27|Financeiro|              4800|         01.01.2019|            Ativo|\n",
            "|    max|                 8|Maria Souza|                34|        Rh|           R$ 5200|         2018/02/01|          Inativo|\n",
            "+-------+------------------+-----------+------------------+----------+------------------+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display the summary statistics of the data\n",
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9WOWYnpDC9-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "-V98aLmOC_9C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
            "| id|         nome|idade|      area|salario|data_de_contratacao|status_de_emprego|\n",
            "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
            "|  1|   João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
            "|  2|  Maria Souza|   30|        Rh|   4800|         15-03-2019|            Ativo|\n",
            "|  4|    Ana Clara|   27| Marketing|   4800|         12/06/2018|            Ativo|\n",
            "|  7|   José Alves|   34| Marketing|   5400|         2018/02/01|          Inativo|\n",
            "|  8|Luciana Costa|   30|Financeiro|R$ 5200|         01.01.2019|            Ativo|\n",
            "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "szj2ImVzDE2P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
            "| id|         nome|idade|      area|salario|data_de_contratacao|status_de_emprego|\n",
            "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
            "|  7|   José Alves|   34| Marketing|   5400|         2018/02/01|          Inativo|\n",
            "|  2|  Maria Souza|   30|        Rh|   4800|         15-03-2019|            Ativo|\n",
            "|  8|Luciana Costa|   30|Financeiro|R$ 5200|         01.01.2019|            Ativo|\n",
            "|  1|   João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
            "|  1|   João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
            "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.orderBy(col('idade').desc()).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "8hD8V8CbHsBP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  1|\n",
            "|  2|\n",
            "|  4|\n",
            "|  7|\n",
            "|  8|\n",
            "+---+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----+\n",
            "|idade|\n",
            "+-----+\n",
            "|   29|\n",
            "|   30|\n",
            "|   27|\n",
            "|   34|\n",
            "|   30|\n",
            "+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ìndice PySpark\n",
        "'''\n",
        "Em PySpark não temos suporte direto à índices, pois os dados\n",
        "não estão alocados em disco, mas podemos fazer ajustes técnicos (gambiarra)\n",
        "como veremos mais pra frente.\n",
        "'''\n",
        "\n",
        "df.select(df.columns[0]).show(5)\n",
        "df.select(col('idade')).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Q_ajekpdIEMX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-----+---------+-------+-------------------+-----------------+\n",
            "| id|      nome|idade|     area|salario|data_de_contratacao|status_de_emprego|\n",
            "+---+----------+-----+---------+-------+-------------------+-----------------+\n",
            "|  7|José Alves|   34|Marketing|   5400|         2018/02/01|          Inativo|\n",
            "+---+----------+-----+---------+-------+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(col('idade') > 30).show(5) # pelo rotulo (cabecalho)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "S4JzlgTAIW67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Row(id=1, nome='João Silva', idade=29, area='Financeiro', salario='5500', data_de_contratacao='01/02/2020', status_de_emprego='Ativo'), Row(id=7, nome='José Alves', idade=34, area='Marketing', salario='5400', data_de_contratacao='2018/02/01', status_de_emprego='Inativo'), Row(id=1, nome='João Silva', idade=29, area='Financeiro', salario='5500', data_de_contratacao='01/02/2020', status_de_emprego='Ativo')]\n",
            "<class 'list'>\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[id: int, nome: string, idade: int, area: string, salario: string, data_de_contratacao: string, status_de_emprego: string]"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rows = df.collect() # retorna uma lista de das linhas (big dataset -> out of memory)\n",
        "# len(rows)\n",
        "\n",
        "select_rows = [rows[x] for x in [0,3,5]]\n",
        "print(select_rows)\n",
        "print(type(select_rows))\n",
        "print('-'*80)\n",
        "\n",
        "df_select_rows = spark.createDataFrame(select_rows, df.schema)\n",
        "df_select_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1s9JzoBnMUw"
      },
      "source": [
        "## Referencias\n",
        "- https://medium.com/@dipan.saha/pyspark-made-easy-day-2-execute-pyspark-on-google-colabs-f3e57da946a\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
